{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised sentiment analyses based on movie reviews\n",
    "## Based on 50,000 labeled IMDb movie reviews [dataset](http://ai.stanford.edu/~amaas/data/sentiment/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Python files with functions\n",
    "import text_normalizer as tn\n",
    "import model_evaluation_utils as meu\n",
    "# ~Python files\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, split (train, test) and normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use subset of the data for better performance\n",
    "train_size = 300\n",
    "test_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  I'm not really much of an Abbott & Costello fa...  negative\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('movie_reviews.csv').sample(frac=1).reset_index(\n",
    "    drop=True)\n",
    "\n",
    "reviews = np.array(dataset['review'])\n",
    "sentiments = np.array(dataset['sentiment'])\n",
    "\n",
    "# train sets\n",
    "train_reviews = reviews[:train_size]\n",
    "train_sentiments = sentiments[:train_size]\n",
    "\n",
    "# test sets\n",
    "test_reviews = reviews[train_size:train_size + test_size]\n",
    "test_sentiments = sentiments[train_size:train_size + test_size]\n",
    "\n",
    "# normalized reviews\n",
    "norm_train_reviews = tn.normalize_corpus(train_reviews)\n",
    "norm_test_reviews = tn.normalize_corpus(test_reviews)\n",
    "\n",
    "# peek at data\n",
    "print(dataset.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional supervised machine learning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# build bag of words (bow) features on train reviews\n",
    "cv = CountVectorizer(min_df=0., max_df=1., ngram_range=(1, 2))\n",
    "cv_train_features = cv.fit_transform(norm_train_reviews)\n",
    "\n",
    "# build tfidf features on train reviews\n",
    "tv = TfidfVectorizer(\n",
    "    min_df=0., max_df=1., ngram_range=(1, 2), sublinear_tf=True)\n",
    "tv_train_features = tv.fit_transform(norm_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform test reviews into features\n",
    "cv_test_features = cv.transform(norm_test_reviews)\n",
    "tv_test_features = tv.transform(norm_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model: train features shape - (300, 39956), test features shape - (1000, 39956)\n",
      "TFIDF model: train features shape - (300, 39956), test features shape - (1000, 39956)\n"
     ]
    }
   ],
   "source": [
    "print('BOW model: train features shape - {}, test features shape - {}'.format(\n",
    "    cv_train_features.shape, cv_test_features.shape))\n",
    "\n",
    "print(\n",
    "    'TFIDF model: train features shape - {}, test features shape - {}'.format(\n",
    "        tv_train_features.shape, tv_test_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation about models to choose for classification\n",
    "+ logistic regression\n",
    "+ SVM\n",
    "+ multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training, prediction and performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty='l2', C=1.0, max_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression on BOW features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.765\n",
      "Precision: 0.7783\n",
      "Recall: 0.765\n",
      "F1 Score: 0.7633\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.84      0.67      0.75       517\n",
      "   negative       0.71      0.86      0.78       483\n",
      "\n",
      "avg / total       0.78      0.77      0.76      1000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive        348      169\n",
      "        negative         66      417\n"
     ]
    }
   ],
   "source": [
    "lr_bow_predictions = meu.train_predict_model(\n",
    "    classifier=lr,\n",
    "    train_features=cv_train_features,\n",
    "    train_labels=train_sentiments,\n",
    "    test_features=cv_test_features,\n",
    "    test_labels=test_sentiments)\n",
    "\n",
    "meu.display_model_performance_metrics(\n",
    "    true_labels=test_sentiments,\n",
    "    predicted_labels=lr_bow_predictions,\n",
    "    classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression on TFIDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.635\n",
      "Precision: 0.7737\n",
      "Recall: 0.635\n",
      "F1 Score: 0.5892\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.96      0.31      0.46       517\n",
      "   negative       0.57      0.99      0.72       483\n",
      "\n",
      "avg / total       0.77      0.64      0.59      1000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive        158      359\n",
      "        negative          6      477\n"
     ]
    }
   ],
   "source": [
    "lr_tfidf_predictions = meu.train_predict_model(\n",
    "    classifier=lr,\n",
    "    train_features=tv_train_features,\n",
    "    train_labels=train_sentiments,\n",
    "    test_features=tv_test_features,\n",
    "    test_labels=test_sentiments)\n",
    "\n",
    "meu.display_model_performance_metrics(\n",
    "    true_labels=test_sentiments,\n",
    "    predicted_labels=lr_tfidf_predictions,\n",
    "    classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "svm = SGDClassifier(loss='hinge', max_iter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM on BOW features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.755\n",
      "Precision: 0.7554\n",
      "Recall: 0.755\n",
      "F1 Score: 0.7551\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.77      0.75      0.76       517\n",
      "   negative       0.74      0.76      0.75       483\n",
      "\n",
      "avg / total       0.76      0.76      0.76      1000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive        388      129\n",
      "        negative        116      367\n"
     ]
    }
   ],
   "source": [
    "svm_bow_predictions = meu.train_predict_model(\n",
    "    classifier=svm,\n",
    "    train_features=cv_train_features,\n",
    "    train_labels=train_sentiments,\n",
    "    test_features=cv_test_features,\n",
    "    test_labels=test_sentiments)\n",
    "\n",
    "meu.display_model_performance_metrics(\n",
    "    true_labels=test_sentiments,\n",
    "    predicted_labels=svm_bow_predictions,\n",
    "    classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM on TFIDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.792\n",
      "Precision: 0.806\n",
      "Recall: 0.792\n",
      "F1 Score: 0.7906\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.87      0.70      0.78       517\n",
      "   negative       0.74      0.89      0.81       483\n",
      "\n",
      "avg / total       0.81      0.79      0.79      1000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive        362      155\n",
      "        negative         53      430\n"
     ]
    }
   ],
   "source": [
    "svm_tfidf_predictions = meu.train_predict_model(\n",
    "    classifier=svm,\n",
    "    train_features=tv_train_features,\n",
    "    train_labels=train_sentiments,\n",
    "    test_features=tv_test_features,\n",
    "    test_labels=test_sentiments)\n",
    "\n",
    "meu.display_model_performance_metrics(\n",
    "    true_labels=test_sentiments,\n",
    "    predicted_labels=svm_tfidf_predictions,\n",
    "    classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes on BOW features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.739\n",
      "Precision: 0.7878\n",
      "Recall: 0.739\n",
      "F1 Score: 0.73\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.91      0.55      0.69       517\n",
      "   negative       0.66      0.94      0.78       483\n",
      "\n",
      "avg / total       0.79      0.74      0.73      1000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive        286      231\n",
      "        negative         30      453\n"
     ]
    }
   ],
   "source": [
    "mnb_bow_predictions = meu.train_predict_model(\n",
    "    classifier=mnb,\n",
    "    train_features=cv_train_features,\n",
    "    train_labels=train_sentiments,\n",
    "    test_features=cv_test_features,\n",
    "    test_labels=test_sentiments)\n",
    "\n",
    "meu.display_model_performance_metrics(\n",
    "    true_labels=test_sentiments,\n",
    "    predicted_labels=mnb_bow_predictions,\n",
    "    classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes on TFIDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.561\n",
      "Precision: 0.7636\n",
      "Recall: 0.561\n",
      "F1 Score: 0.4687\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.99      0.15      0.26       517\n",
      "   negative       0.52      1.00      0.69       483\n",
      "\n",
      "avg / total       0.76      0.56      0.47      1000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive         79      438\n",
      "        negative          1      482\n"
     ]
    }
   ],
   "source": [
    "mnb_tfidf_predictions = meu.train_predict_model(\n",
    "    classifier=mnb,\n",
    "    train_features=tv_train_features,\n",
    "    train_labels=train_sentiments,\n",
    "    test_features=tv_test_features,\n",
    "    test_labels=test_sentiments)\n",
    "\n",
    "meu.display_model_performance_metrics(\n",
    "    true_labels=test_sentiments,\n",
    "    predicted_labels=mnb_tfidf_predictions,\n",
    "    classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newer supervised deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "keras.backend.backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction class label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "num_classes = 2\n",
    "\n",
    "# tokenize train reviews and encode train labels\n",
    "tokenized_train = [tn.tokenizer.tokenize(text) for text in norm_train_reviews]\n",
    "y_tr = le.fit_transform(train_sentiments)\n",
    "y_train = keras.utils.to_categorical(y_tr, num_classes)  # one-hot encoding\n",
    "\n",
    "# tokenize test reviews and encode test labels\n",
    "tokenized_test = [tn.tokenizer.tokenize(text) for text in norm_test_reviews]\n",
    "y_ts = le.fit_transform(test_sentiments)\n",
    "y_test = keras.utils.to_categorical(y_ts, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment class label map:  {'negative': 0, 'positive': 1}\n",
      "------------------------------------------------------------\n",
      "Sample test label transformation: \n",
      "Actual values:  ['positive' 'positive' 'negative']\n",
      "Encoded values:  [1 1 0]\n",
      "One hot encoded values: \n",
      " [[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Sentiment class label map: ',\n",
    "      dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "print('-' * 60)\n",
    "print('Sample test label transformation: ')\n",
    "print('Actual values: ', test_sentiments[:3])\n",
    "print('Encoded values: ', y_ts[:3])\n",
    "print('One hot encoded values: \\n', y_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering with word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build word2vec model\n",
    "w2v_num_features = 500\n",
    "w2v_model = gensim.models.Word2Vec(\n",
    "    tokenized_train,\n",
    "    size=w2v_num_features,\n",
    "    window=150,\n",
    "    min_count=10,\n",
    "    sample=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generating averaged vectors of all words in reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    \n",
    "    def average_word_vectors(words, model, vocabulary, num_features):\n",
    "        feature_vector = np.zeros((num_features, ), dtype='float64')\n",
    "        nwords = 0.\n",
    "\n",
    "        for word in words:\n",
    "            if word in vocabulary:\n",
    "                feature_vector = np.add(feature_vector, model[word])\n",
    "        if nwords:\n",
    "            feature_vector = np.divide(feature_vector, nwords)\n",
    "        return feature_vector\n",
    "\n",
    "    features = [\n",
    "        average_word_vectors(words, model, vocabulary, num_features)\n",
    "        for words in corpus\n",
    "    ]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# generate averaged word vector features from word2vec model\n",
    "avg_wv_train_features = averaged_word2vec_vectorizer(\n",
    "    corpus=tokenized_train, model=w2v_model, num_features=w2v_num_features)\n",
    "avg_wv_test_features = averaged_word2vec_vectorizer(\n",
    "    corpus=tokenized_test, model=w2v_model, num_features=w2v_num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature engineering with GloVe model\n",
    "train_nlp = [tn.nlp(text) for text in norm_train_reviews]\n",
    "train_glove_features = np.array([item.vector for item in train_nlp])\n",
    "\n",
    "test_nlp = [tn.nlp(text) for text in norm_test_reviews]\n",
    "test_glove_features = np.array([item.vector for item in test_nlp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2vec model: train shape - (300, 500), test shape - (1000, 500)\n",
      "GloVe model: train shape - (300, 384), test shape - (1000, 384)\n"
     ]
    }
   ],
   "source": [
    "print('Word2vec model: train shape - {}, test shape - {}'.format(avg_wv_train_features.shape,avg_wv_test_features.shape))\n",
    "print('GloVe model: train shape - {}, test shape - {}'.format(train_glove_features.shape,test_glove_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with deep neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building deep neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_deepnn_architecture(num_input_features):\n",
    "    dnn_model = Sequential()\n",
    "    dnn_model.add(\n",
    "        Dense(512, activation='relu', input_shape=(num_input_features, )))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(512, activation='relu'))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(512, activation='relu'))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(2))\n",
    "    dnn_model.add(Activation('softmax'))\n",
    "\n",
    "    dnn_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "    return dnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training, prediction and performance evaluation based of word2vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_dnn = construct_deepnn_architecture(w2v_num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize sample deep architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"719pt\" viewBox=\"0.00 0.00 224.00 719.00\" width=\"224pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 715)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-715 220,-715 220,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2475224753712 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2475224753712</title>\n",
       "<polygon fill=\"none\" points=\"0,-664.5 0,-710.5 216,-710.5 216,-664.5 0,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"38.5\" y=\"-683.8\">InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"77,-664.5 77,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"77,-687.5 133,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"133,-664.5 133,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"174.5\" y=\"-695.3\">(None, 500)</text>\n",
       "<polyline fill=\"none\" points=\"133,-687.5 216,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"174.5\" y=\"-672.3\">(None, 500)</text>\n",
       "</g>\n",
       "<!-- 2475224753992 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2475224753992</title>\n",
       "<polygon fill=\"none\" points=\"13,-581.5 13,-627.5 203,-627.5 203,-581.5 13,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"38.5\" y=\"-600.8\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"64,-581.5 64,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"64,-604.5 120,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"120,-581.5 120,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-612.3\">(None, 500)</text>\n",
       "<polyline fill=\"none\" points=\"120,-604.5 203,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-589.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2475224753712&#45;&gt;2475224753992 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2475224753712-&gt;2475224753992</title>\n",
       "<path d=\"M108,-664.366C108,-656.152 108,-646.658 108,-637.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"111.5,-637.607 108,-627.607 104.5,-637.607 111.5,-637.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2475224826488 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2475224826488</title>\n",
       "<polygon fill=\"none\" points=\"6.5,-498.5 6.5,-544.5 209.5,-544.5 209.5,-498.5 6.5,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"38.5\" y=\"-517.8\">Dropout</text>\n",
       "<polyline fill=\"none\" points=\"70.5,-498.5 70.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"70.5,-521.5 126.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"126.5,-498.5 126.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-529.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"126.5,-521.5 209.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-506.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2475224753992&#45;&gt;2475224826488 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2475224753992-&gt;2475224826488</title>\n",
       "<path d=\"M108,-581.366C108,-573.152 108,-563.658 108,-554.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"111.5,-554.607 108,-544.607 104.5,-554.607 111.5,-554.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2475224825928 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2475224825928</title>\n",
       "<polygon fill=\"none\" points=\"13,-415.5 13,-461.5 203,-461.5 203,-415.5 13,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"38.5\" y=\"-434.8\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"64,-415.5 64,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"64,-438.5 120,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"120,-415.5 120,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-446.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"120,-438.5 203,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-423.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2475224826488&#45;&gt;2475224825928 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2475224826488-&gt;2475224825928</title>\n",
       "<path d=\"M108,-498.366C108,-490.152 108,-480.658 108,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"111.5,-471.607 108,-461.607 104.5,-471.607 111.5,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2475224788888 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2475224788888</title>\n",
       "<polygon fill=\"none\" points=\"6.5,-332.5 6.5,-378.5 209.5,-378.5 209.5,-332.5 6.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"38.5\" y=\"-351.8\">Dropout</text>\n",
       "<polyline fill=\"none\" points=\"70.5,-332.5 70.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"70.5,-355.5 126.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"126.5,-332.5 126.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-363.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"126.5,-355.5 209.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-340.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2475224825928&#45;&gt;2475224788888 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2475224825928-&gt;2475224788888</title>\n",
       "<path d=\"M108,-415.366C108,-407.152 108,-397.658 108,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"111.5,-388.607 108,-378.607 104.5,-388.607 111.5,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2475225355320 -->\n",
       "<g class=\"node\" id=\"node6\"><title>2475225355320</title>\n",
       "<polygon fill=\"none\" points=\"13,-249.5 13,-295.5 203,-295.5 203,-249.5 13,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"38.5\" y=\"-268.8\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"64,-249.5 64,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"64,-272.5 120,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"120,-249.5 120,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-280.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"120,-272.5 203,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-257.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2475224788888&#45;&gt;2475225355320 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>2475224788888-&gt;2475225355320</title>\n",
       "<path d=\"M108,-332.366C108,-324.152 108,-314.658 108,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"111.5,-305.607 108,-295.607 104.5,-305.607 111.5,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2475225037288 -->\n",
       "<g class=\"node\" id=\"node7\"><title>2475225037288</title>\n",
       "<polygon fill=\"none\" points=\"6.5,-166.5 6.5,-212.5 209.5,-212.5 209.5,-166.5 6.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"38.5\" y=\"-185.8\">Dropout</text>\n",
       "<polyline fill=\"none\" points=\"70.5,-166.5 70.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"70.5,-189.5 126.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"126.5,-166.5 126.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-197.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"126.5,-189.5 209.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-174.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 2475225355320&#45;&gt;2475225037288 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>2475225355320-&gt;2475225037288</title>\n",
       "<path d=\"M108,-249.366C108,-241.152 108,-231.658 108,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"111.5,-222.607 108,-212.607 104.5,-222.607 111.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2475225428600 -->\n",
       "<g class=\"node\" id=\"node8\"><title>2475225428600</title>\n",
       "<polygon fill=\"none\" points=\"13,-83.5 13,-129.5 203,-129.5 203,-83.5 13,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"38.5\" y=\"-102.8\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"64,-83.5 64,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"64,-106.5 120,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"120,-83.5 120,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-114.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"120,-106.5 203,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-91.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 2475225037288&#45;&gt;2475225428600 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>2475225037288-&gt;2475225428600</title>\n",
       "<path d=\"M108,-166.366C108,-158.152 108,-148.658 108,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"111.5,-139.607 108,-129.607 104.5,-139.607 111.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2475216976472 -->\n",
       "<g class=\"node\" id=\"node9\"><title>2475216976472</title>\n",
       "<polygon fill=\"none\" points=\"8,-0.5 8,-46.5 208,-46.5 208,-0.5 8,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"45\" y=\"-19.8\">Activation</text>\n",
       "<polyline fill=\"none\" points=\"82,-0.5 82,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"82,-23.5 138,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"138,-0.5 138,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-31.3\">(None, 2)</text>\n",
       "<polyline fill=\"none\" points=\"138,-23.5 208,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-8.3\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 2475225428600&#45;&gt;2475216976472 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>2475225428600-&gt;2475216976472</title>\n",
       "<path d=\"M108,-83.3664C108,-75.1516 108,-65.6579 108,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"111.5,-56.6068 108,-46.6068 104.5,-56.6069 111.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(\n",
    "    model_to_dot(\n",
    "        w2v_dnn, show_shapes=True, show_layer_names=False,\n",
    "        rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 30 samples\n",
      "Epoch 1/5\n",
      "270/270 [==============================] - ETA: 4s - loss: 3.6661 - acc: 0.400 - ETA: 1s - loss: 6.2007 - acc: 0.477 - ETA: 0s - loss: 6.4068 - acc: 0.520 - ETA: 0s - loss: 6.9556 - acc: 0.509 - 1s 3ms/step - loss: 7.0728 - acc: 0.5148 - val_loss: 6.9084 - val_acc: 0.5667\n",
      "Epoch 2/5\n",
      "270/270 [==============================] - ETA: 0s - loss: 6.4472 - acc: 0.600 - ETA: 0s - loss: 7.2682 - acc: 0.541 - ETA: 0s - loss: 6.9102 - acc: 0.505 - 0s 795us/step - loss: 5.8020 - acc: 0.4926 - val_loss: 8.4046 - val_acc: 0.4333\n",
      "Epoch 3/5\n",
      "270/270 [==============================] - ETA: 0s - loss: 4.9373 - acc: 0.500 - ETA: 0s - loss: 5.2773 - acc: 0.500 - ETA: 0s - loss: 6.2365 - acc: 0.494 - 0s 835us/step - loss: 6.3067 - acc: 0.5296 - val_loss: 6.9845 - val_acc: 0.5667\n",
      "Epoch 4/5\n",
      "270/270 [==============================] - ETA: 0s - loss: 7.5218 - acc: 0.533 - ETA: 0s - loss: 8.0590 - acc: 0.500 - ETA: 0s - loss: 7.7012 - acc: 0.522 - ETA: 0s - loss: 7.6564 - acc: 0.525 - 0s 876us/step - loss: 7.5220 - acc: 0.5333 - val_loss: 6.9845 - val_acc: 0.5667\n",
      "Epoch 5/5\n",
      "270/270 [==============================] - ETA: 0s - loss: 6.9845 - acc: 0.566 - ETA: 0s - loss: 7.3427 - acc: 0.544 - ETA: 0s - loss: 7.3069 - acc: 0.546 - ETA: 0s - loss: 7.6753 - acc: 0.523 - 0s 1ms/step - loss: 7.5218 - acc: 0.5333 - val_loss: 6.9845 - val_acc: 0.5667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2403c1d6a20>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 30\n",
    "w2v_dnn.fit(\n",
    "    x=avg_wv_train_features,\n",
    "    y=y_train,\n",
    "    epochs=5,\n",
    "    batch_size=batch_size,\n",
    "    verbose=True,\n",
    "    shuffle=True,\n",
    "    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred = w2n_dnn.predict_classes(avg_wv_test_features)\n",
    "predictions = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2333\n",
      "Recall: 0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.3146\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.00      0.00      0.00       517\n",
      "   negative       0.48      1.00      0.65       483\n",
      "\n",
      "avg / total       0.23      0.48      0.31      1000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive          0      517\n",
      "        negative          0      483\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(test_sentiments,predictions,classes=['positive','negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training, prediction and performance evaluation based of GloVe features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_dnn = construct_deepnn_architecture(train_glove_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 30 samples\n",
      "Epoch 1/5\n",
      "270/270 [==============================] - ETA: 4s - loss: 0.7579 - acc: 0.433 - ETA: 1s - loss: 0.8959 - acc: 0.466 - ETA: 0s - loss: 0.8369 - acc: 0.446 - ETA: 0s - loss: 0.7835 - acc: 0.495 - 1s 3ms/step - loss: 0.7828 - acc: 0.4963 - val_loss: 0.6552 - val_acc: 0.7000\n",
      "Epoch 2/5\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7431 - acc: 0.366 - ETA: 0s - loss: 0.7045 - acc: 0.491 - ETA: 0s - loss: 0.7209 - acc: 0.483 - 0s 795us/step - loss: 0.7150 - acc: 0.4889 - val_loss: 0.6975 - val_acc: 0.4667\n",
      "Epoch 3/5\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.7117 - acc: 0.600 - ETA: 0s - loss: 0.7274 - acc: 0.555 - ETA: 0s - loss: 0.7141 - acc: 0.550 - 0s 791us/step - loss: 0.7063 - acc: 0.5370 - val_loss: 0.6410 - val_acc: 0.7000\n",
      "Epoch 4/5\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.6621 - acc: 0.633 - ETA: 0s - loss: 0.6837 - acc: 0.591 - ETA: 0s - loss: 0.6847 - acc: 0.571 - 0s 778us/step - loss: 0.6761 - acc: 0.5926 - val_loss: 0.6279 - val_acc: 0.7000\n",
      "Epoch 5/5\n",
      "270/270 [==============================] - ETA: 0s - loss: 0.5467 - acc: 0.766 - ETA: 0s - loss: 0.6929 - acc: 0.583 - ETA: 0s - loss: 0.7238 - acc: 0.557 - 0s 802us/step - loss: 0.7119 - acc: 0.5667 - val_loss: 0.6276 - val_acc: 0.7333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2404f0a24a8>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 30\n",
    "glove_dnn.fit(\n",
    "    x=train_glove_features,\n",
    "    y=y_train,\n",
    "    epochs=5,\n",
    "    batch_size=batch_size,\n",
    "    verbose=True,\n",
    "    shuffle=True,\n",
    "    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred = glove_dnn.predict_classes(test_glove_features)\n",
    "glove_predictions = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.542\n",
      "Precision: 0.6548\n",
      "Recall: 0.542\n",
      "F1 Score: 0.4578\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.79      0.16      0.26       517\n",
      "   negative       0.51      0.95      0.67       483\n",
      "\n",
      "avg / total       0.65      0.54      0.46      1000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive         81      436\n",
      "        negative         22      461\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(test_sentiments,glove_predictions,classes=['positive','negative'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
