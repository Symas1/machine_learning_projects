{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced deep learning supervised sentiment analyses based on movie reviews\n",
    "## Based on 50,000 labeled IMDb movie reviews [dataset](http://ai.stanford.edu/~amaas/data/sentiment/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary depencencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Python files with functions\n",
    "import text_normalizer as tn\n",
    "import model_evaluation_utils as meu\n",
    "# ~Python files\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, split (train, test) and normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use subset of the data for better performance\n",
    "train_size = 300\n",
    "test_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  I saw this with few expectations and absolutel...  positive\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('movie_reviews.csv').sample(frac=1).reset_index(\n",
    "    drop=True)\n",
    "\n",
    "reviews = np.array(dataset['review'])\n",
    "sentiments = np.array(dataset['sentiment'])\n",
    "\n",
    "# train sets\n",
    "train_reviews = reviews[:train_size]\n",
    "train_sentiments = sentiments[:train_size]\n",
    "\n",
    "# test sets\n",
    "test_reviews = reviews[train_size:train_size + test_size]\n",
    "test_sentiments = sentiments[train_size:train_size + test_size]\n",
    "\n",
    "# normalized reviews\n",
    "norm_train_reviews = tn.normalize_corpus(train_reviews)\n",
    "norm_test_reviews = tn.normalize_corpus(test_reviews)\n",
    "\n",
    "# peek at data\n",
    "print(dataset.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = [tn.tokenizer.tokenize(text) for text in norm_train_reviews]\n",
    "tokenized_test = [tn.tokenizer.tokenize(text) for text in norm_test_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build vocabulary mapping (word to index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  7387\n",
      "Sample slice of vocabulary:  {'age': 11, 'movie': 12, 'atypical': 13, 'girl': 14, 'parminder': 15, 'nagra': 16, 'er': 17, 'breakout': 18, 'role': 19, 'play': 20}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# build word to index vocabulary\n",
    "token_counter = Counter(\n",
    "    [token for review in tokenized_train for token in review])\n",
    "vocab_map = {\n",
    "    item[0]: index + 1\n",
    "    for index, item in enumerate(dict(token_counter).items())\n",
    "}\n",
    "max_index = np.max(list(vocab_map.values()))\n",
    "vocab_map['PAD_INDEX'] = 0\n",
    "vocab_map['NOT_FOUND_INDEX'] = max_index + 1\n",
    "vocab_size = len(vocab_map)\n",
    "\n",
    "print('Vocabulary size: ', vocab_size)\n",
    "print('Sample slice of vocabulary: ', dict(list(vocab_map.items())[10:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode and pad data sets and encode prediction class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max review len:  469\n",
      "Train matrix shape:  (300, 469)  Test matrix shape:  (1000, 469)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# get max length of train corpus and initialize label encoder\n",
    "le = LabelEncoder()\n",
    "num_classes = 2\n",
    "max_len = np.max([len(review) for review in tokenized_train])\n",
    "\n",
    "## Train reviews data corpus\n",
    "# Convert tokenized text reviews to numeric vectors\n",
    "train_X = [[vocab_map[token] for token in tokenized_review]\n",
    "           for tokenized_review in tokenized_train]\n",
    "train_X = sequence.pad_sequences(train_X, maxlen=max_len)  # pad\n",
    "train_y = le.fit_transform(train_sentiments)\n",
    "\n",
    "## Test reviews data corpus\n",
    "# Convert tokenized text reviews to numeric vectors\n",
    "test_X = [[\n",
    "    vocab_map[token] if vocab_map.get(token) else vocab_map['NOT_FOUND_INDEX']\n",
    "    for token in tokenized_review\n",
    "] for tokenized_review in tokenized_test]\n",
    "test_X = sequence.pad_sequences(test_X, maxlen=max_len)  # pad\n",
    "test_y = le.transform(test_sentiments)\n",
    "\n",
    "print('Max review len: ',max_len)\n",
    "print('Train matrix shape: ',train_X.shape,' Test matrix shape: ',test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the LSTM model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, SpatialDropout1D\n",
    "from keras.layers import LSTM\n",
    "\n",
    "EMBEDDING_DIM = 128 # dimension for dense embeddings for each token\n",
    "LSTM_DIM = 64 # total LSTM units\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(LSTM_DIM, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 469, 128)          945536    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 469, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 995,009\n",
      "Trainable params: 995,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"78pt\" viewBox=\"0.00 0.00 1069.00 78.00\" width=\"1069pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 74)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-74 1065,-74 1065,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 3127762974144 -->\n",
       "<g class=\"node\" id=\"node1\"><title>3127762974144</title>\n",
       "<polygon fill=\"none\" points=\"0,-0.5 0,-69.5 166,-69.5 166,-0.5 0,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-54.3\">InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"0,-46.5 166,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"78,-23.5 78,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"122\" y=\"-31.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"0,-23.5 166,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"41.5\" y=\"-8.3\">(None, 469)</text>\n",
       "<polyline fill=\"none\" points=\"83,-0.5 83,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"124.5\" y=\"-8.3\">(None, 469)</text>\n",
       "</g>\n",
       "<!-- 3127766163016 -->\n",
       "<g class=\"node\" id=\"node2\"><title>3127766163016</title>\n",
       "<polygon fill=\"none\" points=\"202,-0.5 202,-69.5 396,-69.5 396,-0.5 202,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299\" y=\"-54.3\">Embedding</text>\n",
       "<polyline fill=\"none\" points=\"202,-46.5 396,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"294,-23.5 294,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345\" y=\"-31.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"202,-23.5 396,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243.5\" y=\"-8.3\">(None, 469)</text>\n",
       "<polyline fill=\"none\" points=\"285,-0.5 285,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"340.5\" y=\"-8.3\">(None, 469, 128)</text>\n",
       "</g>\n",
       "<!-- 3127762974144&#45;&gt;3127766163016 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>3127762974144-&gt;3127766163016</title>\n",
       "<path d=\"M166.126,-35C174.513,-35 183.116,-35 191.713,-35\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"191.789,-38.5001 201.789,-35 191.789,-31.5001 191.789,-38.5001\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 3127780704832 -->\n",
       "<g class=\"node\" id=\"node3\"><title>3127780704832</title>\n",
       "<polygon fill=\"none\" points=\"432,-0.5 432,-69.5 654,-69.5 654,-0.5 432,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"543\" y=\"-54.3\">SpatialDropout1D</text>\n",
       "<polyline fill=\"none\" points=\"432,-46.5 654,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"485\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"538,-23.5 538,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"596\" y=\"-31.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"432,-23.5 654,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487.5\" y=\"-8.3\">(None, 469, 128)</text>\n",
       "<polyline fill=\"none\" points=\"543,-0.5 543,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"598.5\" y=\"-8.3\">(None, 469, 128)</text>\n",
       "</g>\n",
       "<!-- 3127766163016&#45;&gt;3127780704832 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>3127766163016-&gt;3127780704832</title>\n",
       "<path d=\"M396.34,-35C404.586,-35 412.992,-35 421.396,-35\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"421.634,-38.5001 431.634,-35 421.634,-31.5001 421.634,-38.5001\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 3127773817544 -->\n",
       "<g class=\"node\" id=\"node4\"><title>3127773817544</title>\n",
       "<polygon fill=\"none\" points=\"690,-0.5 690,-69.5 878,-69.5 878,-0.5 690,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"784\" y=\"-54.3\">LSTM</text>\n",
       "<polyline fill=\"none\" points=\"690,-46.5 878,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"734.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"779,-23.5 779,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"828.5\" y=\"-31.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"690,-23.5 878,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"745.5\" y=\"-8.3\">(None, 469, 128)</text>\n",
       "<polyline fill=\"none\" points=\"801,-0.5 801,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"839.5\" y=\"-8.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 3127780704832&#45;&gt;3127773817544 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>3127780704832-&gt;3127773817544</title>\n",
       "<path d=\"M654.056,-35C662.686,-35 671.381,-35 679.961,-35\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"679.97,-38.5001 689.97,-35 679.969,-31.5001 679.97,-38.5001\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 3127773817432 -->\n",
       "<g class=\"node\" id=\"node5\"><title>3127773817432</title>\n",
       "<polygon fill=\"none\" points=\"914,-0.5 914,-69.5 1061,-69.5 1061,-0.5 914,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"987.5\" y=\"-54.3\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"914,-46.5 1061,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"983,-23.5 983,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1022\" y=\"-31.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"914,-23.5 1061,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"952.5\" y=\"-8.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"991,-0.5 991,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1026\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 3127773817544&#45;&gt;3127773817432 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>3127773817544-&gt;3127773817432</title>\n",
       "<path d=\"M878.082,-35C886.586,-35 895.164,-35 903.57,-35\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"903.723,-38.5001 913.723,-35 903.723,-31.5001 903.723,-38.5001\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import  model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \n",
    "                 rankdir='LR').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 30 samples\n",
      "Epoch 1/5\n",
      "270/270 [==============================] - ETA: 13s - loss: 0.6920 - acc: 0.53 - ETA: 7s - loss: 0.6923 - acc: 0.5167 - ETA: 5s - loss: 0.6937 - acc: 0.466 - ETA: 4s - loss: 0.6930 - acc: 0.475 - ETA: 3s - loss: 0.6935 - acc: 0.473 - ETA: 2s - loss: 0.6932 - acc: 0.477 - ETA: 1s - loss: 0.6932 - acc: 0.481 - ETA: 0s - loss: 0.6931 - acc: 0.487 - 6s 24ms/step - loss: 0.6931 - acc: 0.4889 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "270/270 [==============================] - ETA: 4s - loss: 0.6813 - acc: 0.900 - ETA: 3s - loss: 0.6825 - acc: 0.800 - ETA: 3s - loss: 0.6808 - acc: 0.811 - ETA: 2s - loss: 0.6813 - acc: 0.816 - ETA: 2s - loss: 0.6818 - acc: 0.800 - ETA: 1s - loss: 0.6809 - acc: 0.800 - ETA: 1s - loss: 0.6806 - acc: 0.800 - ETA: 0s - loss: 0.6799 - acc: 0.804 - 5s 19ms/step - loss: 0.6786 - acc: 0.8111 - val_loss: 0.6927 - val_acc: 0.5333\n",
      "Epoch 3/5\n",
      "270/270 [==============================] - ETA: 4s - loss: 0.6609 - acc: 0.933 - ETA: 3s - loss: 0.6644 - acc: 0.916 - ETA: 3s - loss: 0.6623 - acc: 0.900 - ETA: 2s - loss: 0.6553 - acc: 0.925 - ETA: 2s - loss: 0.6526 - acc: 0.933 - ETA: 1s - loss: 0.6506 - acc: 0.927 - ETA: 1s - loss: 0.6493 - acc: 0.909 - ETA: 0s - loss: 0.6476 - acc: 0.900 - 5s 19ms/step - loss: 0.6436 - acc: 0.8963 - val_loss: 0.6911 - val_acc: 0.5667\n",
      "Epoch 4/5\n",
      "270/270 [==============================] - ETA: 4s - loss: 0.6003 - acc: 0.900 - ETA: 3s - loss: 0.5952 - acc: 0.850 - ETA: 3s - loss: 0.5728 - acc: 0.888 - ETA: 2s - loss: 0.5481 - acc: 0.916 - ETA: 2s - loss: 0.5376 - acc: 0.906 - ETA: 1s - loss: 0.5309 - acc: 0.905 - ETA: 1s - loss: 0.5244 - acc: 0.909 - ETA: 0s - loss: 0.5109 - acc: 0.916 - 5s 19ms/step - loss: 0.5218 - acc: 0.9074 - val_loss: 0.6391 - val_acc: 0.6000\n",
      "Epoch 5/5\n",
      "270/270 [==============================] - ETA: 4s - loss: 0.3931 - acc: 0.966 - ETA: 3s - loss: 0.3780 - acc: 0.983 - ETA: 3s - loss: 0.3623 - acc: 0.988 - ETA: 2s - loss: 0.3582 - acc: 0.991 - ETA: 2s - loss: 0.3500 - acc: 0.993 - ETA: 1s - loss: 0.3367 - acc: 0.994 - ETA: 1s - loss: 0.3310 - acc: 0.990 - ETA: 0s - loss: 0.3222 - acc: 0.991 - 5s 19ms/step - loss: 0.3167 - acc: 0.9852 - val_loss: 0.5964 - val_acc: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d83ed0f748>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 30\n",
    "model.fit(train_X, train_y, epochs=5, batch_size=batch_size, \n",
    "          shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict_classes(test_X)\n",
    "predictions = le.inverse_transform(pred_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.692\n",
      "Precision: 0.6991\n",
      "Recall: 0.692\n",
      "F1 Score: 0.6898\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive       0.66      0.78      0.71       494\n",
      "   negative       0.74      0.61      0.67       506\n",
      "\n",
      "avg / total       0.70      0.69      0.69      1000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive        385      109\n",
      "        negative        199      307\n"
     ]
    }
   ],
   "source": [
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predictions, \n",
    "                                      classes=['positive', 'negative'])  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
